{
  "hash": "37f973308c76574fd2d3d0d5882fc150",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"An Updated Comprehensive Tutorial on Transition Network Analysis (TNA)\"\ndescription: |\n    From Raw Event Logs to Network Inference\ndate: \"2026-02-07\"\nauthor: \"Mohammed Saqr\"\ncategories:\n  - learning analytics\n  - tutorial\n  - R\n# engine: markdown\nwarning: false\nmessage: false\nfig.align: center\nformat:\n  html:\n    toc: true\n    toc-depth: 3\n    number-sections: true\n    code-fold: false\n    code-tools: true\n    theme: cosmo\n    self-contained: true\nexecute:\n  warning: false\n  message: false\nknitr:\n  opts_chunk:\n    fig.width: 8\n    fig.height: 6\n    dpi: 600\n    comment: \"#>\"\n---\n\n\n\n\n\n# Introduction\n\nTransition Network Analysis (TNA) is a method for modeling temporal sequences as directed weighted networks. Each unique state (e.g., a learning behavior, an interaction type, or a regulatory action) becomes a node in the network, and each transition between states becomes a directed edge weighted by its estimated probability. TNA provides a rich analytical framework that encompasses visualization, pruning, pattern detection, centrality analysis, community detection, and bootstrapping for statistical inference.\n\nThis tutorial demonstrates the complete TNA workflow using the `tna` R package (version 1.2.0), starting from raw long-format event logs --- the kind of data typically exported from log files, coded interaction data, or learning management systems. We use the built-in `group_regulation_long` dataset, which contains coded collaborative regulation behaviors from student groups.\n\nFor **group comparisons and permutation testing**, see the companion tutorial: [TNA Group Analysis](TNA_Tutorial_Group.html). For **data-driven clustering** of sequences into latent subgroups, see the [TNA Clustering tutorial](TNA_Tutorial_Clustering.html).\n\n## Installation\n\nThe `tna` package is the only package required for this tutorial. It provides all the functions needed for data preparation, model building, visualization, pruning, centrality analysis, community detection, bootstrapping, permutation testing, and sequence analysis --- no additional dependencies need to be loaded.\n\nInstall the stable release from CRAN:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninstall.packages(\"tna\")\n```\n:::\n\n\nAlternatively, install the development version from GitHub to access the latest features:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# install.packages(\"remotes\")  # if not already installed\nremotes::install_github(\"sonsoleslp/tna\")\n```\n:::\n\n\nOnce installed, load the package:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(\"tna\")\n```\n:::\n\n\n# Getting Started with Long-Format Data\n\nThe `tna` package includes `prepare_data()` which is a very powerful function that converts long-format event data into the structure required for TNA. `prepare_data()` handles many tedious issues under the hood and makes using TNA easy and straightforward and less error prone. It also handles ordering, session detection, and --- most importantly --- **preserves metadata columns** (like achievement group, gender, or course) so you can use them later for group comparisons without manual data wrangling.\n\nFor the sake of this tutorial we will use the data set built into TNA but you can use any event data set that has actions, states or behaviors that are ordered or chronologically stored. Let's have a look at the data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load the built-in dataset of coded collaborative regulation behaviors\ndata(\"group_regulation_long\")\nknitr::kable(head(group_regulation_long, 10))\n```\n\n::: {.cell-output-display}\n\n\n| Actor|Achiever | Group|Course |Time                |Action    |\n|-----:|:--------|-----:|:------|:-------------------|:---------|\n|     1|High     |     1|A      |2025-01-01 10:27:07 |cohesion  |\n|     1|High     |     1|A      |2025-01-01 10:35:20 |consensus |\n|     1|High     |     1|A      |2025-01-01 10:42:18 |discuss   |\n|     1|High     |     1|A      |2025-01-01 10:50:00 |synthesis |\n|     1|High     |     1|A      |2025-01-01 10:52:25 |adapt     |\n|     1|High     |     1|A      |2025-01-01 10:57:31 |consensus |\n|     1|High     |     1|A      |2025-01-01 10:58:04 |plan      |\n|     1|High     |     1|A      |2025-01-01 11:05:00 |consensus |\n|     2|High     |     1|A      |2025-01-01 10:27:33 |plan      |\n|     2|High     |     1|A      |2025-01-01 10:33:45 |emotion   |\n\n\n:::\n:::\n\n\nThe `group_regulation_long` dataset has **27,533 rows and 6 columns**. Each row is a single event: an action performed by an actor at a specific point in time, along with metadata columns like `Achiever` (High/Low achievement group).\n\n# Understanding `prepare_data()`\n\nThe `prepare_data()` function is the bridge between your raw event data and TNA:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Convert long-format event log into sequences for TNA\nprepared_data <- prepare_data(\n  group_regulation_long,\n  action = \"Action\",   # column with behavioral states (become network nodes)\n  actor = \"Actor\",     # column with participant IDs (one sequence per actor)\n  time = \"Time\"        # column with timestamps (for ordering and session splitting)\n)\n```\n:::\n\n\n## Arguments\n\nEach argument controls a different aspect of how the raw data is converted into sequences. The **action** argument defines the behaviors or events that serve as nodes in your network model. Without additional arguments, default processing treats all rows as one long continuous sequence. Including **actor** identifies specific participants and shapes the modeling on a per-person basis. This is essential for ensuring that transitions only occur between events from the same individual. The **time** argument uses timestamps to sort events chronologically and handles shuffled data frame rows.\n\n::: {.callout-tip collapse=\"true\"}\n## `action` --- what happened\n\nThe only argument the function technically requires. This is the name of the column that contains the events, states, or behaviors you want to model --- things like \"Plan\", \"Monitor\", \"Discuss\". These become the nodes in your network.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Minimal call --- works, but probably not what you want\nprepared <- prepare_data(df, action = \"Action\")\n```\n:::\n\n\nIf you call `prepare_data()` with just `action`, the function reads every row in the data frame from top to bottom and treats the whole thing as one long sequence. Row 1 transitions to row 2, row 2 transitions to row 3, and so on, all the way down. That means:\n\n-   Every person's events get chained together as if they were one continuous stream. The last event of student A transitions directly into the first event of student B, which makes no sense --- those two events have nothing to do with each other.\n-   The row order in your data frame is the sequence order. If your data is not sorted properly, the transitions will be wrong.\n-   There is no session splitting. If a student did something on Monday and something else on Thursday, those two events are treated as consecutive steps in the same sequence.\n\nFor a classroom observation where one researcher coded one continuous stream of events in real time, this minimal call might actually be fine. But for most research data --- where you have multiple participants, timestamps, or natural breaks between sessions --- you need the other arguments.\n:::\n\n::: {.callout-tip collapse=\"true\"}\n## `actor` --- who did it\n\nThe name of the column identifying who performed the action: a student ID, a user ID, a group ID, whatever defines a unit of analysis. When you include `actor`, the function creates one sequence per actor instead of mashing everyone together.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprepared <- prepare_data(df, action = \"Action\", actor = \"Actor\")\n```\n:::\n\n\nThis is the single most important argument after `action`. Without it, you get one sequence for the whole dataset. With it, you get one sequence per person (or per group, or per whatever your actor column represents). Almost every analysis needs this.\n\nThe function sorts events within each actor by their row order. So if your data is already sorted chronologically within each actor, this is enough. If it is not sorted, you need `time` or `order` to fix that.\n:::\n\n::: {.callout-tip collapse=\"true\"}\n## `time` --- when it happened\n\nThe name of the column containing timestamps. This does two things:\n\n1.  **Sorts events in the right order.** Within each actor, events get sorted by their timestamp, so it does not matter if your data frame rows are shuffled.\n2.  **Splits sequences at gaps.** If two consecutive events from the same actor are more than 15 minutes apart (the default threshold), the function treats them as belonging to different sequences. A student who works from 9:00--9:30, takes a break, and comes back at 10:15 gets two separate sequences instead of one. This matters because a transition from the last event before a break to the first event after a break is not a real transition --- there is a gap in between where the process stopped.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprepared <- prepare_data(df, action = \"Action\", actor = \"Actor\", time = \"Time\")\n```\n:::\n\n\nThe 15-minute default works well for many learning analytics datasets, but your data may need something different. A chat conversation might need a 2-minute threshold. A longitudinal study with weekly sessions might need a 1-day threshold. You can change it with `time_threshold`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 10-minute gap starts a new sequence\nprepared <- prepare_data(\n  df, action = \"Action\", actor = \"Actor\",\n  time = \"Time\", time_threshold = 10 * 60\n)\n\n# 1-hour gap starts a new sequence\nprepared <- prepare_data(\n  df, action = \"Action\", actor = \"Actor\",\n  time = \"Time\", time_threshold = 60 * 60\n)\n```\n:::\n\n\nThe value is in seconds, so multiply minutes by 60 or hours by 3600.\n:::\n\n::: {.callout-tip collapse=\"true\"}\n## `order` --- what came first\n\nSometimes your data does not have timestamps, but it does have a column that tells you the order of events --- a step number, a turn counter, a line number. The `order` argument tells the function to sort events within each actor by that column.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprepared <- prepare_data(df, action = \"Action\", actor = \"Actor\", order = \"step\")\n```\n:::\n\n\nIf both `time` and `order` are provided, data is sorted by `time` first with ties broken by `order`. This is useful when multiple events share the same timestamp and you need a secondary sort criterion.\n:::\n\nAny columns *not* specified as `action`, `actor`, `time`, or `order` are **automatically preserved as metadata**. The `Achiever` column (High/Low) is preserved and can be used later with `group_tna()` for group comparisons.\n\n## Inspecting the Prepared Data\n\nThe output of `prepare_data()` is a list with three parts (sequence data, metadata, and the original long-format data) and will be the input that TNA uses to build the model for analysis.\n\n::: {.callout-tip collapse=\"true\"}\nThe first is the sequences in wide format — a data frame where each row is one sequence and each column is a position, so a sequence of length 7 sits in the first 7 columns and the rest are `NA`. The second is the metadata — a data frame with one row per sequence containing every column from your original data that you didn't assign to `action`, `actor`, `time`, or `order`, things like achievement level or experimental condition. This is how `group_tna()` knows which sequences belong to which group when you write `group_tna(prepared_data, group = \"Achievement\")`. The third is the original long-format data, sorted and tagged with sequence IDs, which functions like `plot_sequences()` and `compare_sequences()` go back to when they need event-level detail. The three parts share the same indexing: row 1 of the wide sequences, row 1 of the metadata, and all long-format rows tagged as sequence 1 all refer to the same actor or session. You can inspect each part with `print(prepared_data, data = \"sequence\")`, `print(prepared_data, data = \"meta\")`, and `print(prepared_data, data = \"long\")`. The whole point is that you run `prepare_data()` once and pass the result to everything else — `tna()`, `group_tna()`, `cluster_sequences()`, `plot_sequences()` — without reshaping anything again.\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# View the wide-format sequence data (rows = sequences, columns = positions)\nprint(prepared_data, data = \"sequence\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> # A tibble: 2,000 × 26\n#>    Action_T1 Action_T2 Action_T3 Action_T4 Action_T5  Action_T6  Action_T7\n#>    <chr>     <chr>     <chr>     <chr>     <chr>      <chr>      <chr>    \n#>  1 cohesion  consensus discuss   synthesis adapt      consensus  plan     \n#>  2 emotion   cohesion  discuss   synthesis <NA>       <NA>       <NA>     \n#>  3 plan      consensus plan      <NA>      <NA>       <NA>       <NA>     \n#>  4 discuss   discuss   consensus plan      cohesion   consensus  discuss  \n#>  5 cohesion  consensus plan      plan      monitor    plan       consensus\n#>  6 discuss   adapt     cohesion  consensus discuss    emotion    cohesion \n#>  7 discuss   emotion   cohesion  consensus coregulate coregulate plan     \n#>  8 cohesion  plan      consensus plan      consensus  discuss    discuss  \n#>  9 emotion   cohesion  emotion   plan      monitor    discuss    emotion  \n#> 10 emotion   cohesion  consensus plan      plan       plan       plan     \n#> # ℹ 1,990 more rows\n#> # ℹ 19 more variables: Action_T8 <chr>, Action_T9 <chr>, Action_T10 <chr>,\n#> #   Action_T11 <chr>, Action_T12 <chr>, Action_T13 <chr>, Action_T14 <chr>,\n#> #   Action_T15 <chr>, Action_T16 <chr>, Action_T17 <chr>, Action_T18 <chr>,\n#> #   Action_T19 <chr>, Action_T20 <chr>, Action_T21 <chr>, Action_T22 <chr>,\n#> #   Action_T23 <chr>, Action_T24 <chr>, Action_T25 <chr>, Action_T26 <chr>\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# View the preserved metadata (e.g., Achiever group) for each sequence\nprint(prepared_data, data = \"meta\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> # A tibble: 2,000 × 7\n#>    .session_id   Actor Achiever Group Course Time                .session_nr\n#>    <chr>         <int> <chr>    <dbl> <chr>  <dttm>                    <int>\n#>  1 1 session1        1 High         1 A      2025-01-01 10:27:07           1\n#>  2 10 session1      10 High         1 A      2025-01-01 10:23:45           1\n#>  3 100 session1    100 High        10 A      2025-01-01 12:11:50           1\n#>  4 1000 session1  1000 High       100 B      2025-01-01 11:12:00           1\n#>  5 1001 session1  1001 Low        101 B      2025-01-01 11:18:40           1\n#>  6 1002 session1  1002 Low        101 B      2025-01-01 11:18:53           1\n#>  7 1003 session1  1003 Low        101 B      2025-01-01 11:18:05           1\n#>  8 1004 session1  1004 Low        101 B      2025-01-01 11:22:26           1\n#>  9 1005 session1  1005 Low        101 B      2025-01-01 11:22:31           1\n#> 10 1006 session1  1006 Low        101 B      2025-01-01 11:15:23           1\n#> # ℹ 1,990 more rows\n```\n\n\n:::\n:::\n\n\n::: {.callout-tip collapse=\"true\"}\n## Other TNA Supported Data Types\n\nThis tutorial uses long-format event data via `prepare_data()`, but `tna()` accepts several other input formats directly. You can choose whichever matches your data.\n\n### Wide Data Frame\n\nEach row is one sequence; each column is a time point. Cell values are categorical state labels. `NA` values are permitted for variable-length sequences. The built-in `group_regulation` dataset is in this format.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(\"group_regulation\")\nhead(group_regulation[, 1:8])\nmodel <- tna(group_regulation)\n```\n:::\n\n\nIf the data frame contains non-sequence columns (e.g., an ID or group variable), use the `cols` argument to select only the sequence columns:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel <- tna(group_regulation, cols = T1:T26)\n```\n:::\n\n\n### Pre-Computed Transition Matrix\n\nA square numeric matrix where element `[i, j]` is the weight of the transition from state `i` to state `j`. Row and column names define the state labels. This is useful when transition probabilities have been estimated externally or obtained from the literature.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmat <- matrix(\n  c(0.1, 0.6, 0.3,\n    0.4, 0.2, 0.4,\n    0.3, 0.3, 0.4),\n  nrow = 3, byrow = TRUE,\n  dimnames = list(c(\"A\", \"B\", \"C\"), c(\"A\", \"B\", \"C\"))\n)\nmodel <- tna(mat)\n\n# Optionally supply initial probabilities:\nmodel <- tna(mat, inits = c(A = 0.5, B = 0.3, C = 0.2))\n```\n:::\n\n\n### TraMineR Sequence Object (`stslist`)\n\nIf you already work with the `TraMineR` package for sequence analysis, you can pass a sequence object created by `TraMineR::seqdef()` directly to `tna()`. The built-in `engagement` dataset is in this format.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(\"engagement\")\nclass(engagement)  # \"stslist\" \"data.frame\"\nmodel <- tna(engagement)\n```\n:::\n\n\n### One-Hot Encoded Data\n\nBinary (0/1) data where each column is a feature and rows represent observations within windows. `import_onehot()` computes co-occurrence weights and returns a `tna` model directly.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel <- import_onehot(binary_data, feature1:feature6, window = \"window_id\")\n```\n:::\n\n\n### Summary\n\n| Input Format | Function | Description |\n|---------------------------|--------------------|-------------------------|\n| Long event log | `prepare_data()` then `tna()` | Timestamped events with actors --- the most common starting point |\n| Wide data frame | `tna(df)` | Rows = sequences, columns = time points |\n| Pre-computed matrix | `tna(mat)` | Square weight matrix with named rows and columns |\n| TraMineR sequence | `tna(seqobj)` | Object from `TraMineR::seqdef()` |\n| One-hot binary data | `import_onehot()` | Co-occurrence model from binary feature data |\n:::\n\n# Building the TNA Model\n\nWith the prepared data in hand, we can now build a TNA model. The `tna()` function estimates a first-order Markov transition probability matrix from the sequences, along with initial state probabilities. This single call produces the core model object used by all subsequent analysis and visualization functions.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Build the TNA model from the prepared sequence data\nmodel <- tna(prepared_data)\n```\n:::\n\n\nThe resulting `model` object contains everything needed for analysis. You can access components with `$` if needed.\n\n::: {.callout-tip collapse=\"true\"}\n## Exploring Model Components\n\n### `model$weights` --- Transition Probability Matrix\n\nEach cell `[i, j]` is the probability of transitioning from state `i` to state `j`. Rows sum to 1.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nknitr::kable(round(model$weights, 3))\n```\n\n::: {.cell-output-display}\n\n\n|           | adapt| cohesion| consensus| coregulate| discuss| emotion| monitor|  plan| synthesis|\n|:----------|-----:|--------:|---------:|----------:|-------:|-------:|-------:|-----:|---------:|\n|adapt      | 0.000|    0.273|     0.477|      0.022|   0.059|   0.120|   0.033| 0.016|     0.000|\n|cohesion   | 0.003|    0.027|     0.498|      0.119|   0.060|   0.116|   0.033| 0.141|     0.004|\n|consensus  | 0.005|    0.015|     0.082|      0.188|   0.188|   0.073|   0.047| 0.396|     0.008|\n|coregulate | 0.016|    0.036|     0.135|      0.023|   0.274|   0.172|   0.086| 0.239|     0.019|\n|discuss    | 0.071|    0.048|     0.321|      0.084|   0.195|   0.106|   0.022| 0.012|     0.141|\n|emotion    | 0.002|    0.325|     0.320|      0.034|   0.102|   0.077|   0.036| 0.100|     0.003|\n|monitor    | 0.011|    0.056|     0.159|      0.058|   0.375|   0.091|   0.018| 0.216|     0.016|\n|plan       | 0.001|    0.025|     0.290|      0.017|   0.068|   0.147|   0.076| 0.374|     0.002|\n|synthesis  | 0.235|    0.034|     0.466|      0.044|   0.063|   0.071|   0.012| 0.075|     0.000|\n\n\n:::\n:::\n\n\n### `model$inits` --- Initial Probabilities\n\nThe probability of starting in each state. In the network plot, these appear as the colored rim around each node.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nknitr::kable(t(round(model$inits, 3)))\n```\n\n::: {.cell-output-display}\n\n\n| adapt| cohesion| consensus| coregulate| discuss| emotion| monitor|  plan| synthesis|\n|-----:|--------:|---------:|----------:|-------:|-------:|-------:|-----:|---------:|\n| 0.012|     0.06|     0.214|      0.019|   0.176|   0.152|   0.144| 0.204|      0.02|\n\n\n:::\n:::\n\n\n### `model$labels` --- State Labels\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel$labels\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] \"adapt\"      \"cohesion\"   \"consensus\"  \"coregulate\" \"discuss\"   \n#> [6] \"emotion\"    \"monitor\"    \"plan\"       \"synthesis\"\n```\n\n\n:::\n:::\n\n\n| Component       | What it tells you                               |\n|-----------------|-------------------------------------------------|\n| `model$weights` | How likely each state-to-state transition is    |\n| `model$inits`   | Where the process typically starts              |\n| `model$labels`  | The names of each node in the network           |\n| `model$data`    | Internal sequence data (used for bootstrapping) |\n:::\n\nThe `summary()` function provides an overview of the model, including the number of states, sequences, and key network-level statistics:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> # A tibble: 13 × 2\n#>    metric                         value\n#>  * <chr>                          <dbl>\n#>  1 Node Count                  9   e+ 0\n#>  2 Edge Count                  7.8 e+ 1\n#>  3 Network Density             1   e+ 0\n#>  4 Mean Distance               4.72e- 2\n#>  5 Mean Out-Strength           1   e+ 0\n#>  6 SD Out-Strength             8.07e- 1\n#>  7 Mean In-Strength            1   e+ 0\n#>  8 SD In-Strength              6.80e-17\n#>  9 Mean Out-Degree             8.67e+ 0\n#> 10 SD Out-Degree               7.07e- 1\n#> 11 Centralization (Out-Degree) 1.56e- 2\n#> 12 Centralization (In-Degree)  1.56e- 2\n#> 13 Reciprocity                 9.86e- 1\n```\n\n\n:::\n:::\n\n\n# Visualizations\n\n## Transition Network Plot\n\nThe core visualization. Nodes represent states, arrows represent transitions (thicker = higher probability), and the colored rim shows initial probability.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# minimum: hide edges below 0.05; cut: fade edges below 0.1\nplot(model, minimum = 0.05, cut = 0.1)\n```\n\n::: {.cell-output-display}\n![Transition network plot](index_files/figure-html/fig-network-1.png){#fig-network width=4800}\n:::\n:::\n\n\n::: {.callout-tip collapse=\"true\"}\n## Key parameters for `plot()`\n\n| Parameter | What it does |\n|--------------------------------|----------------------------------------|\n| `minimum` | Edges with weight below this value are hidden entirely but are retained in all analysis. |\n| `cut` | Edges with weight below this value appear faded/thinner |\n| `edge.label.position` | Position of edge labels along the arrow (0 = start, 1 = end) |\n| `edge.label.cex` | Size of edge labels |\n:::\n\n::: {.callout-tip collapse=\"true\"}\n## Histogram of Edge Weights\n\nShows the distribution of all transition probabilities. Useful for choosing a pruning threshold.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhist(model)\n```\n\n::: {.cell-output-display}\n![Distribution of transition probabilities](index_files/figure-html/fig-hist-1.png){#fig-hist width=4800}\n:::\n:::\n\n:::\n\n## Frequency Distribution of States\n\nHow often each state appears in the data (raw frequency, not transition probability):\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Bar chart of how often each state appears across all sequences\nplot_frequencies(model)\n```\n\n::: {.cell-output-display}\n![Frequency of each regulatory state](index_files/figure-html/fig-frequencies-1.png){#fig-frequencies width=4800}\n:::\n:::\n\n\n# Pruning\n\nA transition probability matrix is almost always fully connected --- every state has some nonzero probability of transitioning to every other state. Pruning removes weak edges so only the *backbone* remains, making the network more readable. However, pruning is purely for visualization and interpretation; it does not affect the underlying model or any analytical results.\n\nThe `prune()` function supports several methods. Below we demonstrate three common approaches: a fixed threshold, removing the lowest proportion, and the disparity filter (a statistically principled backbone extraction method).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Three pruning strategies for comparison\npruned_threshold <- prune(model, method = \"threshold\", threshold = 0.05) # remove edges < 0.05\npruned_lowest    <- prune(model, method = \"lowest\", lowest = 0.05)       # remove bottom 5%\npruned_disparity <- prune(model, method = \"disparity\", level = 0.5)      # disparity filter\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(pruned_disparity)\n```\n\n::: {.cell-output-display}\n![Pruned network using the disparity filter](index_files/figure-html/fig-pruned-1.png){#fig-pruned width=4800}\n:::\n:::\n\n\n::: {.callout-tip collapse=\"true\"}\n## Why Prune?\n\nPruning is not necessary for any analysis --- all edges are retained internally regardless of pruning. Its purpose is to make the network visualization more interpretable by removing weak connections that contribute visual clutter without carrying substantive meaning. The `hist(model)` function (shown above) helps identify a sensible threshold by revealing the distribution of edge weights.\n\nUse `pruning_details()` to inspect what was removed, and `deprune()` to restore the original model.\n:::\n\n::: {.callout-tip collapse=\"true\"}\n## Choosing a Pruning Method\n\n| Method | Logic | Best for |\n|-----------------------|--------------------|-----------------------------|\n| `\"threshold\"` | Remove edges below a fixed weight | Simple; check `hist(model)` first |\n| `\"lowest\"` | Remove the bottom X% of edges | Fixed proportion of the network |\n| `\"disparity\"` | Disparity filter (Serrano et al., 2009) | Statistically principled backbone |\n| `\"bootstrap\"` | Remove non-significant edges | Data-driven pruning via bootstrap |\n\nUse `pruning_details()` to inspect what was removed, and `deprune()` to restore the original.\n:::\n\n# Patterns: Cliques\n\nA clique is a fully connected subnetwork where every state has strong mutual transitions to every other state in the group. Cliques reveal self-reinforcing behavioral loops --- for example, a \"plan -> monitor -> adapt -> plan\" cycle where each state frequently transitions to each of the others.\n\nWe search for cliques of increasing size (dyads, triads, quads). As clique size increases, we lower the threshold because fully mutual connections among more states become increasingly unlikely.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Find cliques of size 2, 3, and 4 with decreasing thresholds\ncliques_of_two   <- cliques(model, size = 2, threshold = 0.1)   # dyads\ncliques_of_three <- cliques(model, size = 3, threshold = 0.05)  # triads\ncliques_of_four  <- cliques(model, size = 4, threshold = 0.03)  # quads\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprint(cliques_of_two)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> Number of 2-cliques = 5 (weight threshold = 0.1)\n#> Showing 5 cliques starting from clique number 1\n#> \n#> Clique 1\n#>             consensus coregulate\n#> consensus  0.08200348 0.18770738\n#> coregulate 0.13451777 0.02335025\n#> \n#> Clique 2\n#>            consensus      plan\n#> consensus 0.08200348 0.3957971\n#> plan      0.29040117 0.3742082\n#> \n#> Clique 3\n#>           discuss    emotion\n#> discuss 0.1948874 0.10579600\n#> emotion 0.1018682 0.07684173\n#> \n#> Clique 4\n#>            consensus   discuss\n#> consensus 0.08200348 0.1880234\n#> discuss   0.32118451 0.1948874\n#> \n#> Clique 5\n#>            cohesion    emotion\n#> cohesion 0.02713864 0.11563422\n#> emotion  0.32534367 0.07684173\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(cliques_of_three)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> Number of 3-cliques = 3 (weight threshold = 0.05)\n#> Showing 3 cliques starting from clique number 1\n#> \n#> Clique 1\n#>            consensus   discuss    emotion\n#> consensus 0.08200348 0.1880234 0.07268131\n#> discuss   0.32118451 0.1948874 0.10579600\n#> emotion   0.32040888 0.1018682 0.07684173\n#> \n#> Clique 2\n#>            consensus    emotion       plan\n#> consensus 0.08200348 0.07268131 0.39579712\n#> emotion   0.32040888 0.07684173 0.09975326\n#> plan      0.29040117 0.14682475 0.37420822\n#> \n#> Clique 3\n#>             consensus coregulate   discuss\n#> consensus  0.08200348 0.18770738 0.1880234\n#> coregulate 0.13451777 0.02335025 0.2736041\n#> discuss    0.32118451 0.08428246 0.1948874\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(cliques_of_four)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> Number of 4-cliques = 5 (weight threshold = 0.03)\n#> Showing 5 cliques starting from clique number 1\n#> \n#> Clique 1\n#>            consensus    emotion    monitor       plan\n#> consensus 0.08200348 0.07268131 0.04661084 0.39579712\n#> emotion   0.32040888 0.07684173 0.03630596 0.09975326\n#> monitor   0.15910677 0.09071877 0.01814375 0.21563154\n#> plan      0.29040117 0.14682475 0.07552379 0.37420822\n#> \n#> Clique 2\n#>              cohesion coregulate    discuss    emotion\n#> cohesion   0.02713864 0.11917404 0.05958702 0.11563422\n#> coregulate 0.03604061 0.02335025 0.27360406 0.17208122\n#> discuss    0.04758289 0.08428246 0.19488737 0.10579600\n#> emotion    0.32534367 0.03419105 0.10186817 0.07684173\n#> \n#> Clique 3\n#>             consensus coregulate   discuss    emotion\n#> consensus  0.08200348 0.18770738 0.1880234 0.07268131\n#> coregulate 0.13451777 0.02335025 0.2736041 0.17208122\n#> discuss    0.32118451 0.08428246 0.1948874 0.10579600\n#> emotion    0.32040888 0.03419105 0.1018682 0.07684173\n#> \n#> Clique 4\n#>              cohesion coregulate    emotion    monitor\n#> cohesion   0.02713864 0.11917404 0.11563422 0.03303835\n#> coregulate 0.03604061 0.02335025 0.17208122 0.08629442\n#> emotion    0.32534367 0.03419105 0.07684173 0.03630596\n#> monitor    0.05582694 0.05792045 0.09071877 0.01814375\n#> \n#> Clique 5\n#>             consensus coregulate    emotion    monitor\n#> consensus  0.08200348 0.18770738 0.07268131 0.04661084\n#> coregulate 0.13451777 0.02335025 0.17208122 0.08629442\n#> emotion    0.32040888 0.03419105 0.07684173 0.03630596\n#> monitor    0.15910677 0.05792045 0.09071877 0.01814375\n```\n\n\n:::\n:::\n\n\n::: {.callout-tip collapse=\"true\"}\n## Why Identify Cliques?\n\nCliques identify subsets of states that form tightly coupled cycles. These are substantively interesting because they represent behavioral patterns that sustain themselves: once a learner enters a clique, the transition probabilities keep them cycling within it. A clique among regulatory states (e.g., Plan, Monitor, Adapt) may indicate an effective self-regulation cycle, whereas a clique among social states may indicate off-task loops.\n:::\n\n::: {layout-ncol=\"3\"}\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(cliques_of_two)\n```\n\n::: {.cell-output-display}\n![Dyad cliques](index_files/figure-html/fig-cliques-dyads-1.png){#fig-cliques-dyads-1 width=3000}\n:::\n\n::: {.cell-output-display}\n![Dyad cliques](index_files/figure-html/fig-cliques-dyads-2.png){#fig-cliques-dyads-2 width=3000}\n:::\n\n::: {.cell-output-display}\n![Dyad cliques](index_files/figure-html/fig-cliques-dyads-3.png){#fig-cliques-dyads-3 width=3000}\n:::\n\n::: {.cell-output-display}\n![Dyad cliques](index_files/figure-html/fig-cliques-dyads-4.png){#fig-cliques-dyads-4 width=3000}\n:::\n\n::: {.cell-output-display}\n![Dyad cliques](index_files/figure-html/fig-cliques-dyads-5.png){#fig-cliques-dyads-5 width=3000}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(cliques_of_three)\n```\n\n::: {.cell-output-display}\n![Triad cliques](index_files/figure-html/fig-cliques-triads-1.png){#fig-cliques-triads-1 width=3000}\n:::\n\n::: {.cell-output-display}\n![Triad cliques](index_files/figure-html/fig-cliques-triads-2.png){#fig-cliques-triads-2 width=3000}\n:::\n\n::: {.cell-output-display}\n![Triad cliques](index_files/figure-html/fig-cliques-triads-3.png){#fig-cliques-triads-3 width=3000}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(cliques_of_four)\n```\n\n::: {.cell-output-display}\n![Quadruple cliques](index_files/figure-html/fig-cliques-quads-1.png){#fig-cliques-quads-1 width=3000}\n:::\n\n::: {.cell-output-display}\n![Quadruple cliques](index_files/figure-html/fig-cliques-quads-2.png){#fig-cliques-quads-2 width=3000}\n:::\n\n::: {.cell-output-display}\n![Quadruple cliques](index_files/figure-html/fig-cliques-quads-3.png){#fig-cliques-quads-3 width=3000}\n:::\n\n::: {.cell-output-display}\n![Quadruple cliques](index_files/figure-html/fig-cliques-quads-4.png){#fig-cliques-quads-4 width=3000}\n:::\n\n::: {.cell-output-display}\n![Quadruple cliques](index_files/figure-html/fig-cliques-quads-5.png){#fig-cliques-quads-5 width=3000}\n:::\n:::\n\n:::\n\n::: {.callout-tip collapse=\"true\"}\n## Parameters and Interpretation\n\n| Parameter | Meaning |\n|---------------------------------------|---------------------------------|\n| `size` | Number of states in each clique (2 = dyads, 3 = triads, etc.) |\n| `threshold` | Minimum transition probability for each edge in the clique |\n| `sum_weights` | If `TRUE`, rank cliques by the sum of edge weights |\n\nLower the threshold as clique size increases, since fully mutual connections become increasingly unlikely.\n:::\n\n# Centralities\n\nCentrality measures reduce each state to a single number capturing its structural importance in the network. Different measures answer different questions: which states are the most common destinations (InStrength), the most common origins (OutStrength), the key bridges connecting other states (Betweenness), or the most influential in spreading activation (Diffusion).\n\n## Node-Level Measures\n\nThe `centralities()` function computes a suite of node-level centrality measures for the model. The resulting plot shows each measure as a separate panel, allowing comparison of which states are most central under each definition.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Compute all centrality measures for each state\nCentralities <- centralities(model)\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(Centralities)\n```\n\n::: {.cell-output-display}\n![Centrality measures for each state](index_files/figure-html/fig-centralities-1.png){#fig-centralities width=4800}\n:::\n:::\n\n\n::: {.callout-tip collapse=\"true\"}\n## What Each Centrality Measure Tells You\n\n| Measure | Interpretation |\n|---------------------------|---------------------------------------------|\n| **OutStrength** | Total outgoing weight. Frequent *origin* state. |\n| **InStrength** | Total incoming weight. \"Attractor\" in the process. |\n| **ClosenessIn / ClosenessOut** | Reachability from/to other states. |\n| **Closeness** | Overall connectedness. |\n| **Betweenness** | Bridge/bottleneck between other states. |\n| **BetweennessRSP** | Robust betweenness via randomized shortest paths. |\n| **Diffusion** | Spread of activation through the network. |\n| **Clustering** | Whether neighbors are also connected to each other. |\n\nCustomize with `measures`, `loops = TRUE`, or `normalize = TRUE`.\n:::\n\n## Edge-Level Measures: Edge Betweenness\n\nWhile node centrality summarizes the importance of individual states, edge betweenness identifies the most critical *transitions* in the network --- the connections that serve as bridges between different parts of the process. Transitions with high edge betweenness lie on many shortest paths and therefore play a key structural role.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Compute edge betweenness for all transitions\nEdge_betweenness <- betweenness_network(model)\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(Edge_betweenness)\n```\n\n::: {.cell-output-display}\n![Edge betweenness network](index_files/figure-html/fig-edge-betweenness-1.png){#fig-edge-betweenness width=4800}\n:::\n:::\n\n\n# Community Detection\n\nCommunities are groups of states that are more densely connected to each other than to the rest of the network. Unlike cliques (which require every pair to be mutually connected), community detection uses modularity-based algorithms to reveal the modular structure and functional subsystems within the transition network.\n\nThe `communities()` function applies a community detection algorithm and assigns each state to a community. The resulting plot colors nodes by their community membership.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Detect communities using the default algorithm (leading eigenvector)\ncomms <- communities(model)\nprint(comms)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> Number of communities found by each algorithm\n#> \n#>         walktrap      fast_greedy       label_prop          infomap \n#>                1                3                1                1 \n#> edge_betweenness    leading_eigen        spinglass \n#>                1                3                2 \n#> \n#> Community assignments\n#> \n#>        state walktrap fast_greedy label_prop infomap edge_betweenness\n#> 1      adapt        1           1          1       1                1\n#> 2   cohesion        1           1          1       1                1\n#> 3  consensus        1           1          1       1                1\n#> 4 coregulate        1           2          1       1                1\n#> 5    discuss        1           2          1       1                1\n#> 6    emotion        1           1          1       1                1\n#> 7    monitor        1           2          1       1                1\n#> 8       plan        1           3          1       1                1\n#> 9  synthesis        1           1          1       1                1\n#>   leading_eigen spinglass\n#> 1             1         1\n#> 2             1         1\n#> 3             2         1\n#> 4             3         2\n#> 5             3         2\n#> 6             1         1\n#> 7             2         2\n#> 8             2         1\n#> 9             3         1\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(comms)\n```\n\n::: {.cell-output-display}\n![Community structure of the transition network](index_files/figure-html/fig-communities-1.png){#fig-communities width=4800}\n:::\n:::\n\n\n::: {.callout-tip collapse=\"true\"}\n## Choosing the Detection Algorithm\n\nUse the `methods` parameter (plural --- you can run several at once):\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncommunities(model, methods = \"leading_eigen\")   # default\ncommunities(model, methods = \"walktrap\")         # random walk based\ncommunities(model, methods = \"fast_greedy\")      # modularity optimization\ncommunities(model, methods = c(\"leading_eigen\", \"walktrap\", \"fast_greedy\"))\n```\n:::\n\n\n| Method            | Logic                                                |\n|-------------------|------------------------------------------------------|\n| `\"leading_eigen\"` | Leading eigenvector of the modularity matrix         |\n| `\"walktrap\"`      | Random walks; nodes visited together belong together |\n| `\"fast_greedy\"`   | Greedy modularity optimization                       |\n| `\"spinglass\"`     | Spin glass model for fine-grained structure          |\n| `\"infomap\"`       | Description length minimization for directed flow    |\n:::\n\n# Bootstrapping\n\n## Why Bootstrap?\n\nThe transition probabilities estimated by `tna()` are descriptive estimates derived from a particular sample of sequences. Without further validation, there is no basis for determining which of these estimates reflect stable properties of the underlying process and which are artifacts of sampling variability. A transition probability of 0.12 may represent a genuine, recurrent pathway --- or it may be an unstable estimate that would shift substantially had a different set of sequences been observed.\n\nBootstrapping addresses this directly by resampling sequences with replacement and reconstructing the transition matrix across a large number of iterations, the procedure generates empirical sampling distributions for each edge weight. This distinguishes transitions that are stable properties of the underlying process from those whose presence is contingent on the particular sample at hand. Edges that do not consistently exceed a defined threshold or that deviate beyond an acceptable consistency range are identified as non-significant, yielding a model in which every retained transition has demonstrated resampling support (Saqr, Lopez-Pernas, & Tikka, 2025).\n\nThe bootstrap is therefore not an optional diagnostic --- it is a confirmatory step that determines whether the network structure warrants substantive interpretation.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(265)  # for reproducibility\n# Resample sequences 1000 times and assess edge stability\nboot <- bootstrap(model, iter = 1000, level = 0.05)\n```\n:::\n\n\n::: {.callout-tip collapse=\"true\"}\n## Bootstrap Arguments\n\n| Argument            | Default         | Meaning                        |\n|---------------------|-----------------|--------------------------------|\n| `iter`              | 1000            | Number of bootstrap resamples  |\n| `level`             | 0.05            | Significance level             |\n| `method`            | `\"stability\"`   | `\"stability\"` or `\"threshold\"` |\n| `consistency_range` | `c(0.75, 1.25)` | Range for consistency check    |\n:::\n\n## Results\n\nThe bootstrap summary reports each edge's observed weight, confidence interval, and whether it survived the stability criterion:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Extract the bootstrap summary table\nboot_df <- boot$summary\nknitr::kable(head(boot_df, 10), digits = 3)\n```\n\n::: {.cell-output-display}\n\n\n|   |from       |to       | weight| p_value|sig   | cr_lower| cr_upper| ci_lower| ci_upper|\n|:--|:----------|:--------|------:|-------:|:-----|--------:|--------:|--------:|--------:|\n|2  |cohesion   |adapt    |  0.003|   0.484|FALSE |    0.002|    0.004|    0.001|    0.006|\n|3  |consensus  |adapt    |  0.005|   0.158|FALSE |    0.004|    0.006|    0.003|    0.006|\n|4  |coregulate |adapt    |  0.016|   0.160|FALSE |    0.012|    0.020|    0.011|    0.022|\n|5  |discuss    |adapt    |  0.071|   0.001|TRUE  |    0.054|    0.089|    0.063|    0.080|\n|6  |emotion    |adapt    |  0.002|   0.575|FALSE |    0.002|    0.003|    0.001|    0.004|\n|7  |monitor    |adapt    |  0.011|   0.337|FALSE |    0.008|    0.014|    0.006|    0.017|\n|8  |plan       |adapt    |  0.001|   0.528|FALSE |    0.001|    0.001|    0.000|    0.002|\n|9  |synthesis  |adapt    |  0.235|   0.001|TRUE  |    0.176|    0.293|    0.201|    0.266|\n|10 |adapt      |cohesion |  0.273|   0.001|TRUE  |    0.205|    0.341|    0.233|    0.313|\n|11 |cohesion   |cohesion |  0.027|   0.095|FALSE |    0.020|    0.034|    0.019|    0.035|\n\n\n:::\n:::\n\n\n::: {.callout-tip collapse=\"true\"}\n## Summary Column Definitions\n\n| Column | Meaning |\n|----|----|\n| `from`, `to` | Source and target state |\n| `weight` | Original observed transition probability |\n| `p_value` | Proportion of inconsistent resamples |\n| `sig` | Whether the edge is significant at the chosen level |\n| `cr_lower`, `cr_upper` | Consistency range bounds |\n| `ci_lower`, `ci_upper` | Bootstrap confidence interval bounds |\n:::\n\nFiltering for significant edges only shows the transitions that constitute the replicable backbone of the network:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Keep only edges that survived the bootstrap and sort by weight\nsig_edges <- boot_df[boot_df$sig == TRUE, ]\nsig_edges <- sig_edges[order(-sig_edges$weight), ]\nknitr::kable(head(sig_edges, 10), digits = 3)\n```\n\n::: {.cell-output-display}\n\n\n|   |from      |to        | weight| p_value|sig  | cr_lower| cr_upper| ci_lower| ci_upper|\n|:--|:---------|:---------|------:|-------:|:----|--------:|--------:|--------:|--------:|\n|20 |cohesion  |consensus |  0.498|   0.001|TRUE |    0.373|    0.622|    0.474|    0.520|\n|19 |adapt     |consensus |  0.477|   0.001|TRUE |    0.358|    0.597|    0.435|    0.522|\n|27 |synthesis |consensus |  0.466|   0.001|TRUE |    0.350|    0.583|    0.430|    0.508|\n|66 |consensus |plan      |  0.396|   0.001|TRUE |    0.297|    0.495|    0.384|    0.408|\n|43 |monitor   |discuss   |  0.375|   0.001|TRUE |    0.282|    0.469|    0.350|    0.398|\n|71 |plan      |plan      |  0.374|   0.001|TRUE |    0.281|    0.468|    0.362|    0.387|\n|15 |emotion   |cohesion  |  0.325|   0.001|TRUE |    0.244|    0.407|    0.308|    0.342|\n|23 |discuss   |consensus |  0.321|   0.001|TRUE |    0.241|    0.401|    0.307|    0.336|\n|24 |emotion   |consensus |  0.320|   0.001|TRUE |    0.240|    0.401|    0.302|    0.338|\n|26 |plan      |consensus |  0.290|   0.001|TRUE |    0.218|    0.363|    0.280|    0.302|\n\n\n:::\n:::\n\n\n## Bootstrapped Network\n\nThe plot below displays only the edges that survived the bootstrap procedure --- each retained transition appeared consistently across 1,000 resampled datasets. Edges absent from this plot were present in the original model but failed to demonstrate resampling stability, and should not be treated as reliable features of the network.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(boot)\n```\n\n::: {.cell-output-display}\n![Bootstrap-significant network](index_files/figure-html/fig-bootstrap-1.png){#fig-bootstrap width=4800}\n:::\n:::\n\n\n::: {.callout-tip collapse=\"true\"}\n## Interpretation\n\n-   **Significant edges** (`sig = TRUE`): appeared consistently across bootstrap resamples. These transitions are stable properties of the data and warrant substantive interpretation.\n-   **Non-significant edges** (`sig = FALSE`): unstable under resampling. Their presence in the original model may reflect sampling noise rather than a genuine transition pathway.\n-   **Narrow confidence intervals**: the edge weight is precisely estimated. **Wide confidence intervals**: substantial uncertainty remains, even if the edge reached significance.\n-   **Practical implication**: report and interpret only the bootstrap-validated network. Conclusions drawn from non-validated edges risk being non-replicable.\n:::\n\n# Centrality Stability\n\n## Why Assess Centrality Stability?\n\nCentrality measures are among the most frequently interpreted yet least frequently validated quantities in network-based analyses. When a researcher reports that \"Monitor has the highest betweenness centrality,\" this claim is meaningful only if that ranking is a stable structural property of the network rather than an artifact of the particular sample. A centrality ordering that deteriorates rapidly under modest data reduction does not constitute a reliable finding; it constitutes a point estimate whose apparent precision is an artifact of the full-sample computation.\n\nThe case-dropping bootstrap addresses this directly. The procedure systematically removes increasing proportions of cases (sequences), recomputes centrality at each step, and quantifies the degree to which the original ranking is preserved through the **Correlation Stability (CS) coefficient** (Epskamp, Borsboom, & Fried, 2018). The CS coefficient represents the maximum proportion of cases that can be dropped while maintaining a correlation of at least 0.7 with the original centrality ordering.\n\n| CS Coefficient | Interpretation |\n|-------------------------------------|-----------------------------------|\n| **\\>= 0.7** | Excellent --- centrality rankings are robust and can be interpreted with confidence |\n| **0.5 -- 0.7** | Acceptable --- rankings are reasonably stable but should be interpreted with some caution |\n| **\\< 0.5** | Poor --- rankings are unreliable and should not serve as the basis for substantive conclusions |\n\nA CS coefficient below 0.5 indicates that the centrality ordering is not sufficiently stable to support claims about which states are \"most central\" or \"most important.\" In such cases, the appropriate response is to collect additional data or to refrain from interpreting centrality rankings altogether.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Case-dropping bootstrap to assess stability of centrality rankings\nCentrality_stability <- estimate_centrality_stability(model)\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(Centrality_stability)\n```\n\n::: {.cell-output-display}\n![Centrality stability across case-dropping proportions](index_files/figure-html/fig-centrality-stability-1.png){#fig-centrality-stability width=4800}\n:::\n:::\n\n\nThe plot shows the average correlation between centrality rankings computed from the full dataset and rankings computed after dropping increasing proportions of cases. A line that remains high (near 1.0) across a wide range of dropped proportions indicates that the centrality ranking is a robust structural property. A line that drops steeply indicates instability.\n\n# Bonus: Sequence Analysis\n\nThe sections above all work with the transition network, where each edge represents how often one state follows another across all sequences. Sequence analysis works with the raw sequences directly, before they get collapsed into a transition matrix. This provides a complementary perspective: visualizing the full temporal unfolding of individual sequences and the overall distribution of states across sequence positions.\n\n## Sequence Plots\n\nThe sequence index plot shows each individual sequence as a horizontal bar, with colors representing states at each position. This reveals patterns in sequence length, composition, and ordering that the transition matrix alone cannot capture.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Each row is one sequence; colors represent states at each position\nplot_sequences(prepared_data)\n```\n\n::: {.cell-output-display}\n![Sequence index plot --- each row is one sequence](index_files/figure-html/fig-sequences-index-1.png){#fig-sequences-index width=4800}\n:::\n:::\n\n\nThe distribution plot aggregates across all sequences and shows, at each position, the proportion of sequences in each state:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Proportion of each state at each sequence position\nplot_sequences(prepared_data, type = \"distribution\")\n```\n\n::: {.cell-output-display}\n![State distribution across sequence positions](index_files/figure-html/fig-sequences-dist-1.png){#fig-sequences-dist width=4800}\n:::\n:::\n\n\n## Simulating Sequences\n\nGenerate synthetic sequences from the fitted model via Markov simulation:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Generate 500 synthetic sequences of up to 20 steps from the fitted model\nsimulated <- simulate(model, nsim = 500, max_len = 20)\nknitr::kable(simulated[1:10, 1:10])\n```\n\n::: {.cell-output-display}\n\n\n|T1        |T2         |T3         |T4        |T5         |T6         |T7        |T8        |T9         |T10        |\n|:---------|:----------|:----------|:---------|:----------|:----------|:---------|:---------|:----------|:----------|\n|discuss   |consensus  |coregulate |monitor   |emotion    |coregulate |plan      |monitor   |emotion    |discuss    |\n|consensus |coregulate |discuss    |consensus |coregulate |emotion    |consensus |plan      |consensus  |plan       |\n|discuss   |emotion    |cohesion   |emotion   |consensus  |plan       |plan      |plan      |plan       |consensus  |\n|monitor   |discuss    |consensus  |emotion   |cohesion   |emotion    |consensus |monitor   |consensus  |discuss    |\n|plan      |monitor    |plan       |monitor   |discuss    |consensus  |discuss   |consensus |coregulate |adapt      |\n|consensus |plan       |consensus  |plan      |emotion    |consensus  |plan      |consensus |plan       |consensus  |\n|emotion   |discuss    |discuss    |discuss   |monitor    |cohesion   |consensus |plan      |consensus  |plan       |\n|discuss   |consensus  |discuss    |emotion   |cohesion   |discuss    |consensus |plan      |plan       |plan       |\n|plan      |plan       |consensus  |plan      |consensus  |consensus  |plan      |emotion   |cohesion   |coregulate |\n|cohesion  |discuss    |emotion    |consensus |plan       |consensus  |monitor   |emotion   |cohesion   |consensus  |\n\n\n:::\n:::\n\n\n::: {.callout-tip collapse=\"true\"}\n## Why Simulate?\n\n-   **Model checking**: compare simulated vs. real data structure\n-   **Power analysis**: how many sequences to detect a given effect?\n-   **Teaching**: generate data with known properties\n:::\n\n## Converting to igraph\n\nIf you want to perform analyses beyond the built-in functions, you can convert the TNA model to an `igraph` object and use the full suite of graph-theoretic tools available in that package.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(igraph)\n# Resolve namespace conflict: igraph::communities() masks tna::communities()\ncommunities <- tna::communities\n\n# Convert TNA model to igraph object for access to igraph's full toolkit\ng <- as.igraph(model)\ncat(\"Clustering coefficient:\", transitivity(g), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> Clustering coefficient: 1\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Diameter:\", diameter(g), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> Diameter: 0.1713767\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"PageRank:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> PageRank:\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(round(page_rank(g)$vector, 4))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>      adapt   cohesion  consensus coregulate    discuss    emotion    monitor \n#>     0.0365     0.0769     0.2358     0.0855     0.1462     0.1088     0.0567 \n#>       plan  synthesis \n#>     0.2150     0.0387\n```\n\n\n:::\n:::\n\n\n# Complete Workflow at a Glance\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(\"tna\")\ndata(\"group_regulation_long\")\n\n# -- Prepare ---------------------------------------------------------------\nprepared_data <- prepare_data(\n  group_regulation_long,\n  action = \"Action\", actor = \"Actor\", time = \"Time\"\n)\n\n# -- Model -----------------------------------------------------------------\nmodel <- tna(prepared_data)\n\n# -- Visualize -------------------------------------------------------------\nplot(model, minimum = 0.05, cut = 0.1)\nhist(model)\nplot_frequencies(model)\n\n# -- Prune -----------------------------------------------------------------\npruned <- prune(model, method = \"disparity\", level = 0.5)\nplot(pruned)\n\n# -- Cliques ---------------------------------------------------------------\nplot(cliques(model, size = 2, threshold = 0.1))\nplot(cliques(model, size = 3, threshold = 0.05))\n\n# -- Centralities ----------------------------------------------------------\nplot(centralities(model))\nplot(betweenness_network(model))\n\n# -- Communities -----------------------------------------------------------\nplot(communities(model, methods = \"leading_eigen\"))\n\n# -- Bootstrap -------------------------------------------------------------\nset.seed(265)\nboot <- bootstrap(model, iter = 1000, level = 0.05)\nplot(boot)\n\n# -- Centrality stability --------------------------------------------------\nplot(estimate_centrality_stability(model))\n\n# -- Sequences -------------------------------------------------------------\nplot_sequences(prepared_data)\nsimulated <- simulate(model, nsim = 500, max_len = 20)\nboot_cliq <- bootstrap_cliques(model, threshold = 0.1, size = 2, iter = 1000)\n```\n:::\n\n\n# Working with Your Own Data {.unnumbered}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_data <- read.csv(\"your_data.csv\")\n\nprepared <- prepare_data(\n  my_data,\n  action = \"event\",\n  actor = \"user_id\",\n  time = \"timestamp\",\n  time_threshold = 900\n)\n\nmodel <- tna(prepared)\nplot(model, minimum = 0.05)\n```\n:::\n\n\n# References {.unnumbered}\n\n-   Saqr, M., López-Pernas, S., Törmänen, T., Kaliisa, R., Misiejuk, K., & Tikka, S. (2025). Transition Network Analysis: A Novel Framework for Modeling, Visualizing, and Identifying the Temporal Patterns of Learners and Learning Processes. In *Proceedings of the 15th International Learning Analytics and Knowledge Conference (LAK '25)* (pp. 351–361). ACM. <https://doi.org/10.1145/3706468.3706513>\n\n-   Tikka, S., López-Pernas, S., & Saqr, M. (2025). tna: An R Package for Transition Network Analysis. *Applied Psychological Measurement*. <https://doi.org/10.1177/01466216251348840>\n\n-   Saqr, M., López-Pernas, S., & Tikka, S. (2025). Mapping Relational Dynamics with Transition Network Analysis: A Primer and Tutorial. In M. Saqr & S. López-Pernas (Eds.), *Advanced Learning Analytics Methods: AI, Precision and Complexity*. Springer. <https://lamethods.org/book2/chapters/ch15-tna/ch15-tna.html>\n\n-   Saqr, M., López-Pernas, S., & Tikka, S. (2025). Capturing The Breadth and Dynamics of the Temporal Processes with Frequency Transition Network Analysis: A Primer and Tutorial. In M. Saqr & S. López-Pernas (Eds.), *Advanced Learning Analytics Methods: AI, Precision and Complexity*. Springer. <https://lamethods.org/book2/chapters/ch16-ftna/ch16-ftna.html>\n\n-   López-Pernas, S., Tikka, S., & Saqr, M. (2025). Mining Patterns and Clusters with Transition Network Analysis: A Heterogeneity Approach. In M. Saqr & S. López-Pernas (Eds.), *Advanced Learning Analytics Methods: AI, Precision and Complexity*. Springer. <https://lamethods.org/book2/chapters/ch17-tna-clusters/ch17-tna-clusters.html>\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}